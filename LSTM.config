[train]
epoch = 10
batch_size = 16
shuffle = True
reader_num = 30
optimizer = adam
learning_rate = 1e-3
step_size = 1
lr_multiplier = 1
grad_accumulate = 1
weight_decay = 1e-3
[distributed]
use = False
backend = nccl
[eval]
batch_size = 16
shuffle = False
reader_num = 30
[data] 
train_dataset_type = JsonFromFiles
train_formatter_type = WordLJP
train_data_path =  input_data/82/zhejiang
train_file_list = train_processed.jsonl

valid_dataset_type = JsonFromFiles
valid_formatter_type = WordLJP
valid_data_path =    input_data/82/zhejiang
valid_file_list = val_processed.jsonl

test_dataset_type = JsonFromFiles
test_formatter_type = WordLJP
test_data_path =   input_data/82/zhejiang
test_file_list = test_processed.jsonl

max_seq_length = 200

word2id =  input_data/82/zhejiang/word2id.pkl
[model]
model_name = LJPLSTM
hidden_size = 50
num_layers = 1
bi_direction = False
dropout = 0.3

[output]
model_path = ./output/model/ljp
model_name = LJPLSTMExercise_81
tensorboard_path = ./output/model/tensorboard
output_function = LJP
